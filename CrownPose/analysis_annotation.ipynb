{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os \n",
    "import time \n",
    "import cv2 \n",
    "import json \n",
    "import imutils\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_annotation = \"/home/asilla/duongnh/datasets/CrownPose/CrowdPose/crowdpose_train.json\"\n",
    "path_annotation = \"/home/asilla/duongnh/project/Analys_CrownPose/AddNose_CrownPose/Converted_Annotation_hrnet.json\"\n",
    "path_image = \"/home/asilla/duongnh/datasets/CrownPose/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_annotation = open(path_annotation, \"r\")\n",
    "dataset = json.load(file_annotation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'categories', 'images', 'annotations'])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_dataset = dataset[\"info\"]\n",
    "categories_dataset = dataset[\"categories\"]\n",
    "images_dataset = dataset[\"images\"]\n",
    "annotations_dataset = dataset[\"annotations\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'CrowdPose annotations modified by MMPose team.', 'year': 2020, 'date_created': '2020/07/01'}\n"
     ]
    }
   ],
   "source": [
    "print(info_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'supercategory': 'person', 'id': 1, 'name': 'person', 'keypoints': ['nose', 'neck', 'right_shoulder', 'right_elbow', 'right_wrist', 'left_shoulder', 'left_elbow', 'left_wrist', 'right_hip', 'right_knee', 'right_ankle', 'left_hip', 'left_knee', 'left_ankle', 'centeroid'], 'skeleton': [[2, 1], [2, 3], [2, 6], [2, 15], [15, 3], [15, 6], [15, 9], [15, 12], [3, 4], [4, 5], [6, 7], [7, 8], [9, 10], [10, 11], [12, 13], [13, 14]]}]\n"
     ]
    }
   ],
   "source": [
    "print(categories_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '103492.jpg', 'id': 103492, 'height': 429, 'width': 640, 'crowdIndex': 0.08}\n"
     ]
    }
   ],
   "source": [
    "print(images_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(annotations_dataset[0][\"iscrowd\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_not_visiable_keypoint(num_kp, l_kp):\n",
    "    count_kp = 0\n",
    "    for i in range(14):\n",
    "        visible = l_kp[i * 3 + 2]\n",
    "        if visible != 0:\n",
    "            count_kp += 1\n",
    "    if count_kp != num_kp:\n",
    "        print(count_kp, num_kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "  \n",
    "  \n",
    "# fontScale\n",
    "fontScale = 0.2\n",
    "   \n",
    "# Blue color in BGR\n",
    "color = (0, 0, 255)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotation(path_annotation):\n",
    "    file_annotation = open(path_annotation,'r')\n",
    "    json_data = json.load(file_annotation)\n",
    "    l_image = json_data['images']\n",
    "    l_annotations = json_data['annotations']\n",
    "    l_bbox = []\n",
    "    l_keypoint = []\n",
    "    l_num_keypoint = []\n",
    "    for annotation in l_annotations:\n",
    "        image_id = annotation[\"image_id\"]\n",
    "        num_keypoints = annotation[\"num_keypoints\"]\n",
    "        print(num_keypoints)\n",
    "        keypoint = annotation[\"keypoints\"]\n",
    "        bbox = annotation[\"bbox\"]\n",
    "        l_bbox.append(bbox)\n",
    "        l_num_keypoint.append(num_keypoints)\n",
    "        l_keypoint.append(keypoint)\n",
    "    return l_bbox, l_keypoint, l_num_keypoint\n",
    "\n",
    "\n",
    "def visualize_bbox(image, bbox,color):\n",
    "    xtop, ytop, width, height = bbox\n",
    "    image = cv2.rectangle(image, (int(xtop), int(ytop)),\\\n",
    "                            (int(xtop + width), int(ytop + height)), color,1)\n",
    "    return image\n",
    "\n",
    "\n",
    "def visualize_keypoint(image, keypoints, color, join_keypoint_categories, annotation):\n",
    "    l_keypoint = []\n",
    "    # if len(keypoints) == 45:\n",
    "    #     confidence_score = annotation[\"confidence_score_nose\"]\n",
    "    #     range_data = 15\n",
    "    #     x = int(keypoints[14 * 3])\n",
    "    #     y = int(keypoints[14 * 3 + 1])\n",
    "    #     image = cv2.putText(image, confidence_score, (x,y), font, \n",
    "    #                0.55, (0,0,255), 1, cv2.LINE_AA)\n",
    "    #     image = cv2.circle(image, (5 + x,y), 5,color, -1)\n",
    "    # else:\n",
    "    #     range_data = 14\n",
    "    for i in range(15):\n",
    "        x = int(keypoints[i * 3])\n",
    "        y = int(keypoints[i * 3 + 1])\n",
    "        visible = int(keypoint[i * 3 + 2])\n",
    "        l_keypoint.append((x,y, visible))\n",
    "        if visible != 0:\n",
    "            image = cv2.circle(image, (x,y), 2,color, -1)\n",
    "    for pair_point in join_keypoint_categories:\n",
    "        start_point_index, end_point_index = pair_point\n",
    "        start_point_index = start_point_index - 1 \n",
    "        end_point_index = end_point_index - 1\n",
    "        if l_keypoint[start_point_index][2] != 0 and l_keypoint[end_point_index][2]:\n",
    "            image = cv2.line(image, (l_keypoint[start_point_index][0], l_keypoint[start_point_index][1]),\\\n",
    "                                    (l_keypoint[end_point_index][0],l_keypoint[end_point_index][1]), color, 1)\n",
    "    return image \n",
    "\n",
    "def check_size_bbox(bbox):\n",
    "    threshold_small = 48 * 48 \n",
    "    xtop, ytop, width, height = bbox\n",
    "    size_bbox = width * height \n",
    "    if size_bbox < threshold_small:\n",
    "        return \"small\"\n",
    "    else:\n",
    "        return \"large\"\n",
    "\n",
    "\n",
    "def valid_num_keypoint(l_annotation):\n",
    "    for annotation in l_annotation:\n",
    "        num_keypoints = annotation[\"num_keypoints\"]\n",
    "        if num_keypoints == 0:\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [2, 3], [2, 6], [2, 15], [15, 3], [15, 6], [15, 9], [15, 12], [3, 4], [4, 5], [6, 7], [7, 8], [9, 10], [10, 11], [12, 13], [13, 14]]\n",
      "14 13\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'line'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Expected sequence length 2, got 3\n>  - Can't parse 'pt1'. Expected sequence length 2, got 3\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_130118/1134521997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mcolor_join\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml_color_keypointjoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex_color_joint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvisualize_keypoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeypoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_join\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_keypoint_categories\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mindex_color_joint\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex_color_joint\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml_color_keypointjoint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_130118/3683056051.py\u001b[0m in \u001b[0;36mvisualize_keypoint\u001b[0;34m(image, keypoints, color, join_keypoint_categories, annotation)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml_keypoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_point_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ml_keypoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_point_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_keypoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_point_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml_keypoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_point_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.5.5) :-1: error: (-5:Bad argument) in function 'line'\n> Overload resolution failed:\n>  - Can't parse 'pt1'. Expected sequence length 2, got 3\n>  - Can't parse 'pt1'. Expected sequence length 2, got 3\n"
     ]
    }
   ],
   "source": [
    "l_image = images_dataset\n",
    "l_annotations = annotations_dataset\n",
    "l_categories = categories_dataset\n",
    "join_keypoint_categories = l_categories[0][\"skeleton\"]\n",
    "print(join_keypoint_categories)\n",
    "\n",
    "dict_image_name = {}\n",
    "dict_image_id = {}\n",
    "\n",
    "for info_image in l_image:\n",
    "    image_id = info_image[\"id\"]\n",
    "    image_name = info_image[\"file_name\"]\n",
    "    dict_image_name[image_name] = image_id\n",
    "\n",
    "for annotation in l_annotations:\n",
    "    \n",
    "    image_id = annotation[\"image_id\"]\n",
    "    num_keypoints = annotation[\"num_keypoints\"]\n",
    "    keypoint = annotation[\"keypoints\"]\n",
    "    bbox = annotation[\"bbox\"]\n",
    "    \n",
    "    if image_id not in dict_image_id:\n",
    "        dict_image_id[image_id] = []\n",
    "        dict_image_id[image_id].append(annotation)\n",
    "    else:\n",
    "        dict_image_id[image_id].append(annotation)\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "fontScale = 2\n",
    "color = (0, 0, 255)\n",
    "thickness = 2\n",
    "l_color_keypointjoint = [(255,0,0), (0,255,255), (255,0,255),(0,140,255),(32,165,218),(0,128,128),(0,100,0),(79,79,47),(204,209,72),(112,25,25),(139,0,139)]\n",
    "count = 0\n",
    "l_count_human = []\n",
    "path_folder_source = \"/home/asilla/duongnh/datasets/CrownPose/images\"\n",
    "path_visualize = \"visualize_hrnet\"\n",
    "count_visualize = 0\n",
    "for file in sorted(os.listdir(path_folder_source)):\n",
    "    count_human = 0\n",
    "    if file not in dict_image_name:\n",
    "        continue \n",
    "    image_id = dict_image_name[file]\n",
    "    l_annotation = dict_image_id[image_id]\n",
    "    \n",
    "    index_color_joint = 0\n",
    "    image = cv2.imread(path_folder_source + \"/\" + file)\n",
    "    for annotation in l_annotation:\n",
    "        num_keypoints = annotation[\"num_keypoints\"]\n",
    "        keypoint = annotation[\"keypoints\"]\n",
    "        bbox = annotation[\"bbox\"]\n",
    "        red = (0,0,255)\n",
    "        blue_light  = (255,255,0)\n",
    "        purple = (239,73,249)\n",
    "        orange = (54, 183, 242)\n",
    "        green = (30,255, 78)\n",
    "        check_not_visiable_keypoint(num_keypoints, keypoint)\n",
    "        type_bbox = check_size_bbox(bbox)\n",
    "       \n",
    "        color_join = l_color_keypointjoint[index_color_joint]\n",
    "        image = visualize_bbox(image, bbox, red)\n",
    "        image = visualize_keypoint(image, keypoint, color_join, join_keypoint_categories, annotation)\n",
    "        index_color_joint += 1\n",
    "        if index_color_joint > len(l_color_keypointjoint) - 1:\n",
    "            index_color_joint = 0\n",
    "    count_visualize += 1\n",
    "    if count_visualize > 50: \n",
    "        break\n",
    "    cv2.imwrite(path_visualize + \"/\" + file, image)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(l_count_human)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1d4c3a7acef685a37c36572b3a166f7e1b7b084a259f94b13cf99b9bb1914a46"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('duongnh')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
